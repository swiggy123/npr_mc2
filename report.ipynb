{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einleitung\n",
    "Question and Answer Generation (QAG) ist ein wichtiger Anwendungsfall, bei dem automatisch Fragen und Antworten zu einem gegebenen Text generiert werden.\n",
    "### Use-Case\n",
    "QAG hat viele praktische Anwendungen:\n",
    "\n",
    "- Content-Erstellung: QAG kann Content-Erstellern und Autoren dabei helfen, Inhalte effizienter zu erstellen. Anstatt manuell Fragen und Antworten zu einem Text zu formulieren, kann QAG dies automatisch erledigen.\n",
    "- E-Learning: In Bildungseinrichtungen und E-Learning-Plattformen kann QAG verwendet werden, um Übungen und Quizfragen zu generieren, die das Verständnis der Schüler und Lernenden fördern.\n",
    "- FAQ-Generierung: Unternehmen können QAG nutzen, um FAQs für ihre Produkte oder Dienstleistungen zu erstellen. Das spart Zeit und Ressourcen bei der Pflege von Kundenunterstützungsseiten.\n",
    "- Chatbots und Virtual Assistants: QAG kann dazu verwendet werden, um Chatbots und virtuellen Assistenten die Fähigkeit zu geben, auf natürliche Weise gestellte Fragen zu beantworten.\n",
    "### Zielsetzung\n",
    "\n",
    "Die Zielsetzung ist: Die Entwicklung eines QAG-Modells, das in der Lage ist, qualitativ hochwertige Fragen und Antworten auf Texte von CNN (https://huggingface.co/datasets/StellarMilk/newsqa) zu generieren.\n",
    "\n",
    "### Github Repo\n",
    "Das für das Training verwendete Repository ist https://github.com/asahi417/lm-question-generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellarchitektur (Jan)\n",
    "\n",
    "Um den Use- Case möglichst gut abzudecken sind wir auf das Paper von Asahi Ushio and Fernando Alva-Manchego and Jose Camacho-Collados gestossen (https://arxiv.org/pdf/2305.17002.pdf), welches unterschiedliche QAG models vergleicht. \n",
    "\n",
    "Das beste beschriebene Modell aufgrund von der Metrik F1/exact match, welches in der Tabelle 2 beschrieben wird ist die T5- end-end Architektur. Zusätzlich zu den besseren Metriken sind die Trainingskosten beim end-end Aufbau besser.\n",
    "\n",
    "### End-End Ansatz\n",
    "Es gibt unterschiedliche QAG-Ansätze. In diesem Bericht wird der Ansatz End2End verwendet, welcher innerhalb eines Modelles und in \"einem Schritt\", sowohl die Frage, wie auch die Antwort erstellt.\n",
    "\n",
    "<img src=\"./images/qag.png\" alt=\"Aufbau\" width=\"500\">\n",
    "\n",
    "### T5- Transformer\n",
    "\n",
    "Der T5- Transformer wird im Paper \"Exploring the Limits of Transfer Learning with a Unified\n",
    "Text-to-Text Transformer\" (https://jmlr.org/papers/volume21/20-074/20-074.pdf) beschrieben.\n",
    "\n",
    "Diese Modelle werden vortrainiert, um dann auf Downstream Tasks angewendet werden zu können. Dabei werden alle Aufgabenstellungen als text-to-text Problem angesehen. Dadurch könnten sehr unterschiedliche Fragestellungen abgebildet werden.\n",
    "\n",
    "<img src=\"./images/T5-Aufbau.png\" alt=\"Aufbau\" width=\"700\">\n",
    "\n",
    "Die Modellarchitektur ist sehr ähnlich wie der ursprüngliche Transformer (https://arxiv.org/pdf/1706.03762.pdf), es wurden aber einzelne Änderungen gemacht:\n",
    "- Layer Normalization: Es wird nur eine vereinfachte Layer-Normalisierung verwendet, welche die Aktivierungen umskaliert, ohne additive Bias hinzuzufügen.\n",
    "- Dropout: Es wird an unterschiedlichen stellen Dropout eingesetzt.\n",
    "- Embedding: Der ursprüngliche Transformer verwendent ein Sinusförmiges Embedding oder ein gelerntes Positionsembedding. In diesem Aufbau wird ein relatives Positionsembedding verwendet.\n",
    "\n",
    "Es gibt noch weitere kleinere Anpassungen. Im grossen und ganzen entspricht es der ursprünglichen Transformerarchitektur.\n",
    "\n",
    "Dabei verwenden wir die folgenden Modellausführungen:\n",
    "\n",
    "#### Modellgrössen\n",
    "\n",
    "Es wurden die Small und Base Varianten untersucht. Diese haben folgende Parameter:\n",
    "\n",
    "| Modeltyp | Output Dimensionalität MLP pro Block | Anzahl Encoder und Decoder Layer |sub-layers and embeddings Dimension|Anzahl Parameter|\n",
    "| :----:   | :---:                                | :-------: |:-------:|:-------:|\n",
    "| Small    | 2048                             |    6     |512|60 * 10^6|\n",
    "| Base     | 3072                                  |    12   |768|220 * 10^6|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsparameter mit Lossfunktion usw...\n",
    "\n",
    "Während des Trainings wird auf eine Kreuzvalidierung verzichtet, da wir die Rechenkapazitäten des Slurm Cluster nicht überstrapazieren möchten. Um Fehler abschätzen zu können, wäre dies Sinnvoll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# Specify the log file path\n",
    "def get_best_model(log_file_path,ckpt_dir=\"small_trained\"):\n",
    "    ckpt_dir = f\"{ckpt_dir}_ckpt\"\n",
    "    # Initialize the best model name variable\n",
    "    best_model_name = None\n",
    "\n",
    "    # Read the log file and extract the best model name\n",
    "    with open(log_file_path, \"r\", encoding=\"UTF-8\") as file:\n",
    "\n",
    "        multiline_text = file.read()\n",
    "    pattern = fr\"creating {ckpt_dir}/best_model\\n(.+?)\\n\"\n",
    "    match = re.search(pattern, multiline_text, re.DOTALL)\n",
    "    if match:\n",
    "        model_path = match.group(1)\n",
    "    else:\n",
    "        print(\"Model path not found.\")\n",
    "    # Regular expression pattern\n",
    "    pattern = fr\"copying\\s+(.*?)\\/epoch_\\d+\\/\\w+\\.json\\s+->\\s+{ckpt_dir}/best_model$\"\n",
    "\n",
    "    # Search for the pattern in the line\n",
    "    match = re.search(pattern, model_path)\n",
    "    if match:\n",
    "        model_path = match.group(1)\n",
    "        return model_path\n",
    "    else:\n",
    "        print(\"Model path not found in the line.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_loss(log_file_path,best_model_name):\n",
    "    # Initialize empty lists to store names, epochs, steps, and loss values\n",
    "    names = []\n",
    "    epochs = []\n",
    "    steps = []\n",
    "    loss_values = []\n",
    "\n",
    "    # Define regular expression patterns to extract name, epoch, step, and loss values\n",
    "    name_pattern = r\"initialize checkpoint at (.+)\"\n",
    "    epoch_pattern = r\"\\[epoch (\\d+)/\"\n",
    "    step_pattern = r\"\\(global step (\\d+): loss: ([\\d.]+), lr: ([\\d.]+)\"\n",
    "    average_pattern = r'average loss:\\s*([\\d.]+)'\n",
    "    average_losses = []\n",
    "    epochs_for_avg_losses = []\n",
    "    current_epoch = 0  # Initialize the current_epoch to 0\n",
    "    current_name = None\n",
    "    inside_target = False  # Flag to indicate if we are inside the target section\n",
    "    # Read the log file and extract name, epoch, step, and loss values using regex\n",
    "    with open(log_file_path, \"r\", encoding=\"UTF-8\") as log_file:\n",
    "        for line in log_file:\n",
    "            name_match = re.search(name_pattern, line)\n",
    "            if name_match:\n",
    "                current_name = name_match.group(1)\n",
    "            if f\"{best_model_name}\" in line:\n",
    "                if inside_target:\n",
    "                    break  # Stop if we reach the second occurrence of the target\n",
    "                else:\n",
    "                    inside_target = True  # Start recording when we find the first occurrence\n",
    "                    continue\n",
    "\n",
    "            if inside_target:\n",
    "                epoch_match = re.search(epoch_pattern, line)\n",
    "                step_match = re.search(step_pattern, line)\n",
    "                # Find all matches in the text\n",
    "                average_match = re.findall(average_pattern, line)\n",
    "\n",
    "                # Extract the average loss if it's present in a line\n",
    "                if average_match:\n",
    "                    average_loss = float(average_match[0])\n",
    "                    average_losses.append(average_loss)\n",
    "                    epochs_for_avg_losses.append(current_epoch)\n",
    "                if epoch_match:\n",
    "                    current_epoch = int(epoch_match.group(1)) +1\n",
    "                elif step_match:\n",
    "                    step = int(step_match.group(1))\n",
    "                    loss = float(step_match.group(2))\n",
    "                    names.append(current_name)\n",
    "                    epochs.append(current_epoch)\n",
    "                    steps.append(step)\n",
    "                    loss_values.append(loss)\n",
    "\n",
    "    # Create a Pandas DataFrame\n",
    "    data = {\n",
    "        \"Name\": names,\n",
    "        \"Epoch\": epochs,\n",
    "        \"Step\": steps,\n",
    "        \"Loss\": loss_values\n",
    "    }\n",
    "\n",
    "    df_steps = pd.DataFrame(data)\n",
    "    data_avg_los = pd.DataFrame({\n",
    "        \"Epoch\": epochs_for_avg_losses,\n",
    "\n",
    "        \"Loss\": average_losses\n",
    "    })\n",
    "\n",
    "    return df_steps,data_avg_los\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_path = \"./slurm/logs/train_base_err.txt\"\n",
    "ckpt_dir = \"base_trained\"\n",
    "name = get_best_model(log_file_path ,ckpt_dir=ckpt_dir)\n",
    "df,average_loss = get_loss(log_file_path,name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datengrundlage (Sowohl EDA wie auch beschreiben (newsqa usw.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erroranalyse (min. 3 Stück) (Florin)\n",
    "\n",
    "Evaluation Small -> welche Fehler macht das Modell?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbesserungvorschläge und dazugehörige Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erklärung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weitere Ideen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
