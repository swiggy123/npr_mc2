{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Einleitung\n",
    "Question and Answer Generation (QAG) ist ein wichtiger Anwendungsfall, bei dem automatisch Fragen und Antworten zu einem gegebenen Text generiert werden.\n",
    "### Use-Case\n",
    "QAG hat viele praktische Anwendungen:\n",
    "\n",
    "- Content-Erstellung: QAG kann Content-Erstellern und Autoren dabei helfen, Inhalte effizienter zu erstellen. Anstatt manuell Fragen und Antworten zu einem Text zu formulieren, kann QAG dies automatisch erledigen.\n",
    "- E-Learning: In Bildungseinrichtungen und E-Learning-Plattformen kann QAG verwendet werden, um Übungen und Quizfragen zu generieren, die das Verständnis der Schüler und Lernenden fördern.\n",
    "- FAQ-Generierung: Unternehmen können QAG nutzen, um FAQs für ihre Produkte oder Dienstleistungen zu erstellen. Das spart Zeit und Ressourcen bei der Pflege von Kundenunterstützungsseiten.\n",
    "- Chatbots und Virtual Assistants: QAG kann dazu verwendet werden, um Chatbots und virtuellen Assistenten die Fähigkeit zu geben, auf natürliche Weise gestellte Fragen zu beantworten.\n",
    "### Zielsetzung\n",
    "\n",
    "Die Zielsetzung ist: Die Entwicklung eines QAG-Modells, das in der Lage ist, qualitativ hochwertige Fragen und Antworten auf Texte von CNN (https://huggingface.co/datasets/StellarMilk/newsqa) zu generieren.\n",
    "\n",
    "### Github Repo\n",
    "Das für das Training verwendete Repository ist https://github.com/asahi417/lm-question-generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modellarchitektur (Jan)\n",
    "\n",
    "Um den Use- Case möglichst gut abzudecken sind wir auf das Paper von Asahi Ushio and Fernando Alva-Manchego and Jose Camacho-Collados gestossen (https://arxiv.org/pdf/2305.17002.pdf), welches unterschiedliche QAG models vergleicht. \n",
    "\n",
    "Das beste beschriebene Modell aufgrund von der Metrik F1/exact match, welches in der Tabelle 2 beschrieben wird ist die T5- end-end Architektur. Zusätzlich zu den besseren Metriken sind die Trainingskosten beim end-end Aufbau besser.\n",
    "\n",
    "### End-End Ansatz\n",
    "Es gibt unterschiedliche QAG-Ansätze. In diesem Bericht wird der Ansatz End2End verwendet, welcher innerhalb eines Modelles und in \"einem Schritt\", sowohl die Frage, wie auch die Antwort erstellt.\n",
    "\n",
    "<img src=\"./images/qag.png\" alt=\"Aufbau\" width=\"500\">\n",
    "\n",
    "### T5- Transformer\n",
    "\n",
    "Der T5- Transformer wird im Paper \"Exploring the Limits of Transfer Learning with a Unified\n",
    "Text-to-Text Transformer\" (https://jmlr.org/papers/volume21/20-074/20-074.pdf) beschrieben.\n",
    "\n",
    "Diese Modelle werden vortrainiert, um dann auf Downstream Tasks angewendet werden zu können. Dabei werden alle Aufgabenstellungen als text-to-text Problem angesehen. Dadurch könnten sehr unterschiedliche Fragestellungen abgebildet werden.\n",
    "\n",
    "<img src=\"./images/T5-Aufbau.png\" alt=\"Aufbau\" width=\"700\">\n",
    "\n",
    "Die Modellarchitektur ist sehr ähnlich wie der ursprüngliche Transformer (https://arxiv.org/pdf/1706.03762.pdf), es wurden aber einzelne Änderungen gemacht:\n",
    "- Layer Normalization: Es wird nur eine vereinfachte Layer-Normalisierung verwendet, welche die Aktivierungen umskaliert, ohne additive Bias hinzuzufügen.\n",
    "- Dropout: Es wird an unterschiedlichen stellen Dropout eingesetzt.\n",
    "- Embedding: Der ursprüngliche Transformer verwendent ein Sinusförmiges Embedding oder ein gelerntes Positionsembedding. In diesem Aufbau wird ein relatives Positionsembedding verwendet.\n",
    "\n",
    "Es gibt noch weitere kleinere Anpassungen. Im grossen und ganzen entspricht es der ursprünglichen Transformerarchitektur.\n",
    "\n",
    "Dabei verwenden wir die folgenden Modellausführungen:\n",
    "\n",
    "#### Modellgrössen\n",
    "\n",
    "Es wurden die Small und Base Varianten untersucht. Diese haben folgende Parameter:\n",
    "\n",
    "| Modeltyp | Output Dimensionalität MLP pro Block | Anzahl Encoder und Decoder Layer |sub-layers and embeddings Dimension|Anzahl Parameter|\n",
    "| :----:   | :---:                                | :-------: |:-------:|:-------:|\n",
    "| Small    | 2048                             |    6     |512|60 * 10^6|\n",
    "| Base     | 3072                                  |    12   |768|220 * 10^6|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsprozess\n",
    "\n",
    "Für das Trainieren des Modells wurde die Package lmqg verwendet, welche vom Repository [asahi417/lm-question-generation](https://github.com/asahi417/lm-question-generation) stammt. Jedoch hatten wir beim Trainingsprozess Probleme mit der Metrik \"METEOR\", welche eine JAVA Runtime benötigte und somit das Training auf dem I4DS verhinderte. Das hat uns dazu veranlasst, die Package zu forken und zu editieren. Unser Fork ist unter [swiggy123/lm-question-generation](https://github.com/swiggy123/lm-question-generation) zu finden.\n",
    "\n",
    "Mit der LMQG CLI Schnittstelle konnte das Modell simpel trainiert werden. Wir trainierten das Modell basierend auf den Hyperparametern des ACL 2023 Papers, welche hier zu finden sind: [2023_acl_qag/model_finetuning.end2end.sh](https://github.com/asahi417/lm-question-generation/blob/master/misc/2023_acl_qag/model_finetuning.end2end.sh). Unser Trainingsprozess wurde Beispielweise beim t5-small Modell so gestartet:\n",
    "\n",
    "```bash\n",
    "lmqg-train-search -d \"StellarMilk/newsqa\" -m \"t5-small\" -b 2 -g 2 4 -c \"small_trained_ckpt\" -i 'paragraph' -o 'questions_answers' -p 'qag' --epoch-partial 10 -e 15 --max-length-output-eval 512 --max-length-output 512\n",
    "```\n",
    "\n",
    "Wobei die Parameter folgendes bedeuten:\n",
    "|        Parameter         |                                Beschreibung                                 |   Gewählter Wert   |\n",
    "| :----------------------: | :-------------------------------------------------------------------------: | :----------------: |\n",
    "|            -d            |              Hugging Face Dataset, das verwendet werden soll.               | StellarMilk/newsqa |\n",
    "|            -m            |                         Modell, das trainiert wird.                         |      t5-small      |\n",
    "|            -b            |                                Batchgrösse.                                 |         2          |\n",
    "|            -g            |                    Schritte für Gradientenakkumulation.                     |      2 oder 4      |\n",
    "|            -c            |                            Pfad für Checkpoint.                             | small_trained_ckpt |\n",
    "|            -i            |                         Input-Spalte des Datasets.                          |     paragraph      |\n",
    "|            -o            |                         Output-Spalte des Datasets.                         | questions_answers  |\n",
    "|            -p            |                              Modelltyp-Prefix.                              |        qag         |\n",
    "|     --epoch-partial      |   Anzahl der Epochen, die in der ersten Trainingsphase trainiert werden.    |         10         |\n",
    "|            -e            | Mindestanzahl der Epochen, die in der zweiten Trainingsphase erreicht wird. |         15         |\n",
    "| --max-length-output-eval |      Maximale Sequenzlänge für die Ausgabesequenz bei der Evaluation.       |        512         |\n",
    "|   --max-length-output    |                Maximale Sequenzlänge für die Ausgabesequenz.                |        512         |\n",
    "\n",
    "Das Modell wird in einem 2-Phasen Hyperparameteroptimierungsprozess trainiert, welche in dieser Grafik dargestellt ist:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/asahi417/lm-question-generation/master/assets/grid_search.png\" alt=\"Trainingsprozess\" width=\"800\"><br>\n",
    "\n",
    "In unserem Beispiel werden in der ersten Phase 12 Modelle 10 Epochen trainiert. Danach werden die besten 5 Modelle gewählt und in der zweiten Phase 5 weitere Epochen trainiert (Total 5). Falls das beste Modell bei der Epoche 15 am besten ist, wird dieses Modell weitertrainiert, bis die Validierungsmetrik (standardmässig BLEU-4) nicht mehr besser wird. Falls das beste Modell bei der Epoche 15 nicht am besten ist, wird das Modell mit der besten Metrik gewählt und nicht weitertrainiert.\n",
    "\n",
    "### Modellliste\n",
    "Hier eine Liste aller trainierten und/oder evaluierten Modelle:\n",
    "|                  Modellname                   | Beschreibung                                                        | Evaluationsordner                 | Selbst trainiert? |\n",
    "| :-------------------------------------------- | :------------------------------------------------------------------ | :-------------------------------- | :---------------- |\n",
    "|            lmqg/t5-base-squad-qag             | T5-Baseline Modell, welches auf SQuAD trainiert wurde.              | evaluation_base/                  | Nein              |\n",
    "|    StellarMilk/t5-base-newsqa-qag-trained     | T5-Baseline Modell, welches auf NewsQA trainiert wurde.             | evaluation_base_trained/          | Ja                |\n",
    "|            lmqg/t5-small-squad-qag            | T5-Small Modell, welches auf SQuAD trainiert wurde.                 | evaluation_small/                 | Nein              |\n",
    "|    StellarMilk/t5-small-newsqa-qag-trained    | T5-Small Modell, welches auf NewsQA trainiert wurde.                | evaluation_small_trained          | Ja                |\n",
    "|   StellarMilk/t5-small-newsqa-qag-finetuned   | lmqg/t5-small-squad-qag Modell, welches auf NewsQA weitertrainiert wurde. | evaluation_small_finetuned        | Ja                |\n",
    "| StellarMilk/t5-small-squad-newsqa-qag-trained | T5-Small Modell, welches auf SQuAD und NewsQA trainiert wurde.      | evaluation_small_combined_trained | Ja |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainingsparameter mit Lossfunktion usw...\n",
    "\n",
    "Während des Trainings wird auf eine Kreuzvalidierung verzichtet, da wir die Rechenkapazitäten des Slurm Cluster nicht überstrapazieren möchten. Um Fehler abschätzen zu können, wäre dies Sinnvoll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>Step</th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base_trained_ckpt/model_mzgdpa</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0.494186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>base_trained_ckpt/model_mzgdpa</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0.520353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>base_trained_ckpt/model_mzgdpa</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0.463166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>base_trained_ckpt/model_mzgdpa</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>0.321157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>base_trained_ckpt/model_mzgdpa</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.325742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>base_trained_ckpt/model_mzgdpa</td>\n",
       "      <td>9</td>\n",
       "      <td>6000</td>\n",
       "      <td>0.277301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>base_trained_ckpt/model_mzgdpa</td>\n",
       "      <td>9</td>\n",
       "      <td>6050</td>\n",
       "      <td>0.220752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>base_trained_ckpt/model_mzgdpa</td>\n",
       "      <td>9</td>\n",
       "      <td>6100</td>\n",
       "      <td>0.194521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>base_trained_ckpt/model_mzgdpa</td>\n",
       "      <td>9</td>\n",
       "      <td>6150</td>\n",
       "      <td>0.193140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>base_trained_ckpt/model_mzgdpa</td>\n",
       "      <td>9</td>\n",
       "      <td>6200</td>\n",
       "      <td>0.172138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name  Epoch  Step      Loss\n",
       "0    base_trained_ckpt/model_mzgdpa      0    50  0.494186\n",
       "1    base_trained_ckpt/model_mzgdpa      0   100  0.520353\n",
       "2    base_trained_ckpt/model_mzgdpa      0   150  0.463166\n",
       "3    base_trained_ckpt/model_mzgdpa      0   200  0.321157\n",
       "4    base_trained_ckpt/model_mzgdpa      0   250  0.325742\n",
       "..                              ...    ...   ...       ...\n",
       "119  base_trained_ckpt/model_mzgdpa      9  6000  0.277301\n",
       "120  base_trained_ckpt/model_mzgdpa      9  6050  0.220752\n",
       "121  base_trained_ckpt/model_mzgdpa      9  6100  0.194521\n",
       "122  base_trained_ckpt/model_mzgdpa      9  6150  0.193140\n",
       "123  base_trained_ckpt/model_mzgdpa      9  6200  0.172138\n",
       "\n",
       "[124 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "\n",
    "log_file_path = \"./slurm/logs/train_base_err.txt\"\n",
    "ckpt_dir = \"base_trained\"\n",
    "\n",
    "name = utils.get_best_model(log_file_path, ckpt_dir=ckpt_dir)\n",
    "df, average_loss = utils.get_loss(log_file_path, name)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datengrundlage (Sowohl EDA wie auch beschreiben (newsqa usw.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erroranalyse (min. 3 Stück) (Florin)\n",
    "\n",
    "Evaluation Small -> welche Fehler macht das Modell?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verbesserungvorschläge und dazugehörige Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erklärung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weitere Ideen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fazit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
