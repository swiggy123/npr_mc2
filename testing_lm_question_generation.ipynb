{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m venv myenv\n",
    "# source myenv/bin/activate  # On Windows use `myenv\\Scripts\\activate`\n",
    "#!pip install lmqg\n",
    "# python -m spacy download en_core_web_sm\n",
    "\n",
    "# import os\n",
    "# if os.getcwd().endswith(\"npr_mc2\"):\n",
    "#     os.chdir(\"./lm-question-generation/\")\n",
    "from pprint import pprint\n",
    "from lmqg import TransformersQG\n",
    "import pandas as pd\n",
    "from lmqg import GridSearcher\n",
    "import sys\n",
    "sys.path.insert(0,\"./lm-question-generation/lmqg/\")\n",
    "from lmqg_cl.qag_evaluation import run_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 501.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Who was an English painter who specialised in watercolour landscapes?',\n",
      "  'William Turner'),\n",
      " ('What is William Turner often known as?',\n",
      "  'William Turner of Oxford or just Turner of Oxford'),\n",
      " (\"What did many of Turner's paintings depict?\",\n",
      "  'the countryside around Oxford'),\n",
      " (\"What is one of Turner's best known pictures?\",\n",
      "  'a view of the city of Oxford from Hinksey Hill')]\n"
     ]
    }
   ],
   "source": [
    "context = \"William Turner was an English painter who specialised in watercolour landscapes. He is often known \" \\\n",
    "          \"as William Turner of Oxford or just Turner of Oxford to distinguish him from his contemporary, \" \\\n",
    "          \"J. M. W. Turner. Many of Turner's paintings depicted the countryside around Oxford. One of his \" \\\n",
    "          \"best known pictures is a view of the city of Oxford from Hinksey Hill.\"\n",
    "# model prediction\n",
    "question_answer = model.generate_qa(context)\n",
    "pprint(question_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qa']\n",
      "[('context', 'qa', 'qag')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1033: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\modeling_utils.py:2570: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\utils\\hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = GridSearcher(\n",
    "    checkpoint_dir='tmp_ckpt',\n",
    "    dataset_path=\"./data/data/train.csv\",\n",
    "    input_types= \"context\",\n",
    "    output_types= \"qa\",\n",
    "    prefix_types = \"qag\",\n",
    "    model='lmqg/t5-base-squad-qag',\n",
    "    max_length=512,\n",
    "    max_length_output=256,\n",
    "    epoch=2,\n",
    "    batch=8,\n",
    "    n_max_config=5,\n",
    "    gradient_accumulation_steps=[8], \n",
    "    lr=[1e-04],\n",
    "    label_smoothing=[0.15],\n",
    "    random_seed=1,\n",
    "    fp16=False\n",
    ")\n",
    "out = trainer.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-27 11:32:45 INFO     generate qa for split test\n",
      "2023-11-27 11:32:45 INFO     found 0 empty prediction from 2\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1977.51it/s]\n",
      "2023-11-27 11:32:50 INFO     found 0 empty prediction from 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.56 seconds, 5.76 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 89.95it/s]\n",
      "2023-11-27 11:32:55 INFO     found 0 empty prediction from 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.53 seconds, 5.87 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 221.83it/s]\n",
      "2023-11-27 11:33:00 INFO     found 0 empty prediction from 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.48 seconds, 6.10 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n",
      "2023-11-27 11:33:01 INFO     found 0 empty prediction from 2\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.63it/s]\n",
      "2023-11-27 11:33:01 INFO     found 0 empty prediction from 2\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.82it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 167.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.13 seconds, 0.94 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.06it/s]\n",
      "2023-11-27 11:33:08 INFO     generate qa for split validation\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\models\\auto\\tokenization_auto.py:671: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\models\\auto\\configuration_auto.py:1033: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\modeling_utils.py:2570: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\j\\github\\lm-question-generation\\myenv\\lib\\site-packages\\transformers\\utils\\hub.py:374: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "2023-11-27 11:33:14 INFO     use spaCy answer extraction model: positionrank\n",
      "2023-11-27 11:33:15 INFO     Model `lmqg/t5-large-squad-qag`\n",
      "2023-11-27 11:33:15 INFO     \t * Num of GPU in use: 0\n",
      "2023-11-27 11:33:15 INFO     \t * Prefix: True\n",
      "2023-11-27 11:33:15 INFO     \t * Language: en (ignore at the training phase)\n",
      "2023-11-27 11:33:16 INFO     model prediction: (qag model)\n",
      "2023-11-27 11:33:16 INFO     running model for `question_answer_pair_generation`\n",
      "2023-11-27 11:33:16 INFO     encode all the data       : 2\n",
      "100%|██████████| 2/2 [00:00<00:00, 226.59it/s]\n",
      "2023-11-27 11:33:16 INFO     after remove the overflow : 2\n",
      "2023-11-27 11:34:14 INFO     found 0 empty prediction from 2\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 198.44it/s]\n",
      "2023-11-27 11:34:18 INFO     found 0 empty prediction from 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.46 seconds, 6.18 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 249.56it/s]\n",
      "2023-11-27 11:34:23 INFO     found 0 empty prediction from 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.47 seconds, 6.13 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 236.35it/s]\n",
      "2023-11-27 11:34:27 INFO     found 0 empty prediction from 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.43 seconds, 6.29 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "2023-11-27 11:34:28 INFO     found 0 empty prediction from 2\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.07it/s]\n",
      "2023-11-27 11:34:28 INFO     found 0 empty prediction from 2\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.13it/s]\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 2.13 seconds, 0.94 sentences/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.95it/s]\n"
     ]
    }
   ],
   "source": [
    "args_list = [\"-m\", \"lmqg/t5-base-squad-qag\", \"-e\", \"./evaluate_lm_question_generation/\", \"-d\", \"./data/data/test.csv\", \"-l\", \"en\"]\n",
    "df = run_evaluation(args_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
